{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines with Python and Scikit-learn \n",
    "####  The step towards more structured and cleaner data science projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents concept of pipelines with practical implementation in python and sklearn library. My goal is to clearly explain what pipelines are what benefits come with using them in your project workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some initial steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make some needed imports and read example dataset we will work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, Imputer, FunctionTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, make_union, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "data = pd.read_csv('../data/data_sample', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1159515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>668304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME_INCOME_TYPE NAME_CONTRACT_TYPE CODE_GENDER  AMT_INCOME_TOTAL  \\\n",
       "0               Working         Cash loans           F           72000.0   \n",
       "1  Commercial associate         Cash loans           M          198000.0   \n",
       "2               Working         Cash loans           F          157500.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_REQ_CREDIT_BUREAU_MON  TARGET  \n",
       "0    180000.0                        0.0       0  \n",
       "1   1159515.0                        0.0       1  \n",
       "2    668304.0                        0.0       0  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 7 columns):\n",
      "NAME_INCOME_TYPE             30000 non-null object\n",
      "NAME_CONTRACT_TYPE           30000 non-null object\n",
      "CODE_GENDER                  30000 non-null object\n",
      "AMT_INCOME_TOTAL             30000 non-null float64\n",
      "AMT_CREDIT                   30000 non-null float64\n",
      "AMT_REQ_CREDIT_BUREAU_MON    25597 non-null float64\n",
      "TARGET                       30000 non-null int64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are six variables with binary classification target. Dataset intensionally consists of various types: string, categorical, continuous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('TARGET', axis=1), data['TARGET'], test_size=0.30, stratify = data['TARGET'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without any pipelines yet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bunch of operations we perform almost in every data science project. Before we start explaining pipelines, let's demonstrate some examples, because it will help us to understand pipelines later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE                0\n",
       "NAME_CONTRACT_TYPE              0\n",
       "CODE_GENDER                     0\n",
       "AMT_INCOME_TOTAL                0\n",
       "AMT_CREDIT                      0\n",
       "AMT_REQ_CREDIT_BUREAU_MON    3105\n",
       "dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['AMT_REQ_CREDIT_BUREAU_MON'] = X_train['AMT_REQ_CREDIT_BUREAU_MON'].fillna(0)\n",
    "X_test['AMT_REQ_CREDIT_BUREAU_MON'] = X_test['AMT_REQ_CREDIT_BUREAU_MON'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME_INCOME_TYPE             0\n",
       "NAME_CONTRACT_TYPE           0\n",
       "CODE_GENDER                  0\n",
       "AMT_INCOME_TOTAL             0\n",
       "AMT_CREDIT                   0\n",
       "AMT_REQ_CREDIT_BUREAU_MON    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(X_train['CODE_GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['CODE_GENDER'] = le.transform(X_train['CODE_GENDER'])\n",
    "X_test['CODE_GENDER'] = le.transform(X_test['CODE_GENDER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log transformation of continuous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['AMT_INCOME_TOTAL'] = np.log(X_train['AMT_INCOME_TOTAL'])\n",
    "X_test['AMT_INCOME_TOTAL'] = np.log(X_test['AMT_INCOME_TOTAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>0</td>\n",
       "      <td>12.196022</td>\n",
       "      <td>1671210.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>1</td>\n",
       "      <td>12.419166</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22997</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>0</td>\n",
       "      <td>12.382125</td>\n",
       "      <td>182016.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>0</td>\n",
       "      <td>11.407565</td>\n",
       "      <td>101880.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>State servant</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>0</td>\n",
       "      <td>11.967181</td>\n",
       "      <td>1113840.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NAME_INCOME_TYPE NAME_CONTRACT_TYPE  CODE_GENDER  AMT_INCOME_TOTAL  \\\n",
       "3334   Commercial associate         Cash loans            0         12.196022   \n",
       "8434              Pensioner    Revolving loans            1         12.419166   \n",
       "22997  Commercial associate         Cash loans            0         12.382125   \n",
       "14401  Commercial associate         Cash loans            0         11.407565   \n",
       "27944         State servant         Cash loans            0         11.967181   \n",
       "\n",
       "       AMT_CREDIT  AMT_REQ_CREDIT_BUREAU_MON  \n",
       "3334    1671210.0                        0.0  \n",
       "8434     630000.0                        0.0  \n",
       "22997    182016.0                        0.0  \n",
       "14401    101880.0                        0.0  \n",
       "27944   1113840.0                        0.0  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization of variables with different scales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.fit(X_train[['AMT_INCOME_TOTAL','AMT_CREDIT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['AMT_INCOME_TOTAL','AMT_CREDIT']] = scalar.transform(X_train[['AMT_INCOME_TOTAL','AMT_CREDIT']])\n",
    "X_test[['AMT_INCOME_TOTAL','AMT_CREDIT']] = scalar.transform(X_test[['AMT_INCOME_TOTAL','AMT_CREDIT']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode text variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False, separator='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict = X_train[['NAME_INCOME_TYPE','NAME_CONTRACT_TYPE']].to_dict('records')\n",
    "X_test_dict = X_test[['NAME_INCOME_TYPE','NAME_CONTRACT_TYPE']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float64'>, separator='_', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit\n",
    "dv.fit(X_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform\n",
    "X_train_encoded = dv.transform(X_train_dict)\n",
    "X_test_encoded = dv.transform(X_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge encoded columns with X_train\n",
    "cols = dv.get_feature_names()\n",
    "X_train_encoded = pd.DataFrame(X_train_encoded, index=X_train.index, columns=cols)\n",
    "X_test_encoded = pd.DataFrame(X_test_encoded, index=X_test.index, columns=cols)\n",
    "\n",
    "X_train_trans = pd.concat([X_train_encoded, X_train.drop(['NAME_INCOME_TYPE', 'NAME_CONTRACT_TYPE'], axis=1)], axis=1)\n",
    "X_test_trans = pd.concat([X_test_encoded, X_test.drop(['NAME_INCOME_TYPE', 'NAME_CONTRACT_TYPE'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check performance on training set and predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what is Pipeline?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`official scikit-learn documentation:`\n",
    "\n",
    "Sequentially apply a list of transforms and a final estimator. \n",
    "\n",
    "`StackOverFlow:`\n",
    "\n",
    "Pipeline is a useful tool for encapsulating multiple different transformers alongside an estimator into one object, so that you only have to call your methods on your raw data once.\n",
    "\n",
    "\n",
    "In other words think about pipelines as a series of transformations performed on your data. You feed pipeline with raw data, it goes as input to the first transformer, then output from that transformer is input to the second transformer and so on... Last element in pipeline can be either transformer or estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For example\n",
    "\n",
    "```\n",
    "Data -> [ Select variables ] -> [ Normalize ] -> [ Reduce dimensions ] -> [ Logistic Regression ] -> Output\n",
    "```\n",
    "\n",
    "`[ Select variables ]` - transformer for selecting variables\n",
    "\n",
    "`[ Normalize ]` - normalization step\n",
    "\n",
    "`[ Reduce dimensions ]` - dimension reduction\n",
    "\n",
    "`[ Logistic Regression ]` - estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformers** are for data preparation. They have two method `fit` and `transform`. \n",
    "\n",
    "`Fit` finds parameters from training data, if needed, and `transform` apply defined transformation to training or test data. \n",
    "\n",
    "**Estimator** are for modeling. With  `fit` you train your model and you make prediction with `predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Transformer - StandardScaler** \n",
    "\n",
    "\n",
    "• `fit` – find mean, standard deviation of each feature\n",
    "\n",
    "• `transform` – subtract mean, then divide by standard deviation\n",
    "\n",
    "\n",
    "#### **Estimator - LogisticRegression**\n",
    "\n",
    "\n",
    "• `fit` – find coefficients in logistic regression formula\n",
    "\n",
    "• `predict` – plug into formula, get predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for simplicity let's consider only one variable and build our first **Pipelines**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_var1 = X_train.loc[:, ['AMT_INCOME_TOTAL']]\n",
    "X_test_var1 = X_test.loc[:, ['AMT_INCOME_TOTAL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use two transformers from sklearn library, `Imputer` and `StandardScaler`. The former is for completing missing values, the latter standardize features by removing the mean and scaling to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We put steps together in a Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('standardizer', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And just write this:\n",
    "X_train_final = pipe.fit_transform(X_train_var1)\n",
    "X_test_final = pipe.transform(X_test_var1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As simple as that! We just apply series of transformations and receive final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's directly include estimator in pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('standardizer', StandardScaler()),\n",
    "    ('logReg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train_var1, y_train)\n",
    "y_pred = pipe.predict(X_test_var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We applied exacly the same transformations and made prediction at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice!** Pipeline help us to prevent **data leakage**. When we call method `predict` on test data, pipelines use previously learnt parameters on train data and apply only `transform` methods to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **make_pipeline** notation instead of Pipeline. It just simpler shortcut and works exactly the same as code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    Imputer(),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "#### Set parameters in Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('imputer',\n",
       "   Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)),\n",
       "  ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "             penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "             verbose=0, warm_start=False))],\n",
       " 'imputer': Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0),\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'imputer__axis': 0,\n",
       " 'imputer__copy': True,\n",
       " 'imputer__missing_values': 'NaN',\n",
       " 'imputer__strategy': 'mean',\n",
       " 'imputer__verbose': 0,\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'ovr',\n",
       " 'logisticregression__n_jobs': 1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'liblinear',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='most_frequent',\n",
       "    verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=False, with_std=True)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'imputer__strategy':'most_frequent', 'standardscaler__with_mean':False}\n",
    "\n",
    "pipe.set_params(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "**Note:**  You can even use Pipeline with **GridSearch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### Transformers in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real project we almost always need to make diffrent independent transformation on the same original variable. Up till now our examples were pipeline you can think about as a single stream. Now we will use `FeatureUnion` which let us perform parallel transformations. Analogously to make_pipeline `maek_union` is a shortcut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.pipeline.make_union`\n",
    "\n",
    "    Creates a union of transformers\n",
    "    \n",
    "    ```\n",
    "    \n",
    "             transformer 1\n",
    "           /               \\\n",
    "          /                 \\\n",
    "    input                     output\n",
    "          \\                 /    \n",
    "           \\               /\n",
    "             transformer 2\n",
    "             \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>0.620290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>1.083136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22997</th>\n",
       "      <td>1.006305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>-1.015134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>0.145626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AMT_INCOME_TOTAL\n",
       "3334           0.620290\n",
       "8434           1.083136\n",
       "22997          1.006305\n",
       "14401         -1.015134\n",
       "27944          0.145626"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_var1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_paral = make_pipeline(\n",
    "    Imputer(),    \n",
    "    make_union(\n",
    "        FunctionTransformer(np.sin),\n",
    "        FunctionTransformer(lambda x: x+10),\n",
    "        FunctionTransformer(lambda x: x+20)\n",
    "    ),\n",
    "    FunctionTransformer(lambda x: x+1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Scheme:\n",
    "    ```\n",
    "    \n",
    "                         transformer: np.sin\n",
    "                       /                     \\\n",
    "                      /                       \\\n",
    "    input -- Imputer  -- transformer: x+10   --  -- transformer: x+1 -- output\n",
    "                      \\                       /    \n",
    "                       \\                     /\n",
    "                         transformer: x+20\n",
    "             \n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipe_paral.fit_transform(X_train_var1)\n",
    "X_test = pipe_paral.transform(X_test_var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.58127143, 11.62029032, 21.62029032],\n",
       "       [ 1.88343168, 12.08313627, 22.08313627],\n",
       "       [ 1.84486084, 12.006305  , 22.006305  ],\n",
       "       ...,\n",
       "       [ 0.15044899,  9.98486645, 19.98486645],\n",
       "       [ 0.54627965, 10.52906428, 20.52906428],\n",
       "       [ 1.77419559, 11.88544321, 21.88544321]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown on a scheme above, we apply three parallel tranformation to original data and receive three columns with differently tranformed original variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a real life projects, situation is almost never as simple as in presented examples. Normally datasets are a mix of:\n",
    "- categorical features\n",
    "- numerical features\n",
    "- dates\n",
    "- text data\n",
    "- with missing values / without missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible transformations for **categorical features** are _one hot encoding_, which is converting to binary values, _convert to numerical values_ by using a hash of categorical variable, _target averaging_ which means replacing categorical feature with an average of the target.\n",
    "    \n",
    "For **numerical features** it could be _fill missing values, create bins with ranges, normalize, scale_. \n",
    "\n",
    "For **text** some common transformations are _bag of words vectorization, word2vec, sentence2vec_. \n",
    "\n",
    "From **dates** we often extract years, months, days, days of week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to preprocess all these types of data using **one pipeline**. It's clear that depends on problem we solve, there will be specific cases. Therefore will need to build our customer transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remind, our original example data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1159515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>668304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>251280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>227520.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME_INCOME_TYPE NAME_CONTRACT_TYPE CODE_GENDER  AMT_INCOME_TOTAL  \\\n",
       "0               Working         Cash loans           F           72000.0   \n",
       "1  Commercial associate         Cash loans           M          198000.0   \n",
       "2               Working         Cash loans           F          157500.0   \n",
       "3  Commercial associate         Cash loans           F          171000.0   \n",
       "4             Pensioner         Cash loans           M          135000.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_REQ_CREDIT_BUREAU_MON  TARGET  \n",
       "0    180000.0                        0.0       0  \n",
       "1   1159515.0                        0.0       1  \n",
       "2    668304.0                        0.0       0  \n",
       "3    251280.0                        0.0       1  \n",
       "4    227520.0                        NaN       0  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split data once again:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('TARGET', axis=1), data['TARGET'], test_size=0.30, stratify = data['TARGET'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here are some simple custom tranformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoNothingTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Template Transformer class, which does nothing.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdderTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Tranformer, which add some value.\n",
    "    \"\"\"\n",
    "    def __init__(self, add=0):\n",
    "        self.add = add\n",
    "        \n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        return x + self.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Tranformer, which selects particular column.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if our custom tranformers work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    Selector(['AMT_INCOME_TOTAL']),\n",
    "    AdderTransformer(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>198020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>247520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22997</th>\n",
       "      <td>238520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14401</th>\n",
       "      <td>90020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27944</th>\n",
       "      <td>157520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AMT_INCOME_TOTAL\n",
       "3334           198020.0\n",
       "8434           247520.0\n",
       "22997          238520.0\n",
       "14401           90020.0\n",
       "27944          157520.0"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit_transform(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a **final example** we will build pipeline to preprocess our example dataset. We will include the same tranformations as performed in a introduction of this notebook, so you could easily compare with pipeline approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>1159515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Working</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>668304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NAME_INCOME_TYPE NAME_CONTRACT_TYPE CODE_GENDER  AMT_INCOME_TOTAL  \\\n",
       "0               Working         Cash loans           F           72000.0   \n",
       "1  Commercial associate         Cash loans           M          198000.0   \n",
       "2               Working         Cash loans           F          157500.0   \n",
       "\n",
       "   AMT_CREDIT  AMT_REQ_CREDIT_BUREAU_MON  TARGET  \n",
       "0    180000.0                        0.0       0  \n",
       "1   1159515.0                        0.0       1  \n",
       "2    668304.0                        0.0       0  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanData(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xt = X.copy()\n",
    "        Xt[\"AMT_REQ_CREDIT_BUREAU_MON\"] = Xt[\"AMT_REQ_CREDIT_BUREAU_MON\"].fillna(0)\n",
    "        \n",
    "        return Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatText(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns, concat_name):\n",
    "        self.columns = columns\n",
    "        self.concat_name = concat_name\n",
    "    \n",
    "    def fit(self, X, *args):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X[self.concat_name] = ''\n",
    "        for col in self.columns:\n",
    "            X[self.concat_name] += ' '\n",
    "            X[self.concat_name] += X[col]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_records(df):\n",
    "    return df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    CleanData(),\n",
    "    ConcatText(['NAME_INCOME_TYPE', 'NAME_CONTRACT_TYPE'], 'concat_text'),\n",
    "    FeatureUnion([\n",
    "        ('GenderEncode', make_pipeline(Selector(['CODE_GENDER']), FunctionTransformer(to_records, validate=False), DictVectorizer(sparse=False))), \n",
    "        ('logTrans', make_pipeline(Selector(['AMT_INCOME_TOTAL']), FunctionTransformer(np.log))),\n",
    "        ('Scalar', make_pipeline(Selector(['AMT_INCOME_TOTAL','AMT_CREDIT']), StandardScaler())),\n",
    "        ('TextEncode', make_pipeline(Selector(['concat_text']), FunctionTransformer(to_records, validate=False), DictVectorizer(sparse=False))), \n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pipeline.fit_transform(X_train)\n",
    "X_test_final = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 15)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Including estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    CleanData(),\n",
    "    ConcatText(['NAME_INCOME_TYPE', 'NAME_CONTRACT_TYPE'], 'concat_text'),\n",
    "    FeatureUnion([\n",
    "        ('GenderEncode', make_pipeline(Selector(['CODE_GENDER']), FunctionTransformer(to_records, validate=False), DictVectorizer(sparse=False))), \n",
    "        ('logTrans', make_pipeline(Selector(['AMT_INCOME_TOTAL']), FunctionTransformer(np.log))),\n",
    "        ('Scalar', make_pipeline(Selector(['AMT_INCOME_TOTAL','AMT_CREDIT']), StandardScaler())),\n",
    "        ('TextEncode', make_pipeline(Selector(['concat_text']), FunctionTransformer(to_records, validate=False), DictVectorizer(sparse=False))), \n",
    "    ]),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cleandata', CleanData()), ('concattext', ConcatText(columns=['NAME_INCOME_TYPE', 'NAME_CONTRACT_TYPE'],\n",
       "      concat_name='concat_text')), ('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('GenderEncode', Pipeline(memory=None,\n",
       "     steps=[('selector', Selector(column=['CODE_...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:\n",
    "- **Pipelines make your project more structured and manageable.** It pays off especially with time, when project is getting bigger and bigger, when it comes to hyperparameters tunning etc.) \n",
    "- **Your code is reusable.**\n",
    "\n",
    "Disadvantages:\n",
    "- **Initial investment is higher.**\n",
    "- **It is originally designed to output numpy array.** Full integration with pandas dataframe requires some custom modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources to get more:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Official library: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog post: http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture about pipelines: https://www.youtube.com/watch?v=BFaadIqWlAg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
